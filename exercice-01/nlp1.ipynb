{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rodrigo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rodrigo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/rodrigo/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "stop_words=set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb.csv\", delimiter=\";\")\n",
    "df = df.iloc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"\"Love in the Time of Money\"\" ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"\"Love in the Time of Money\"\" ...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_tags(html):\n",
    "    soup = BeautifulSoup(html)\n",
    "    return soup.get_text()\n",
    "df['review'] = df['review'].apply(clean_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"\"Love in the Time of Money\"\" ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"\"Love in the Time of Money\"\" ...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return \" \".join(tokenizer.tokenize(text))\n",
    "df['review'] = df['review'].apply(clean_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there s a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei s Love in the Time of Money is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production The filming tech...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there s a family where a little boy ...  negative\n",
       "4  Petter Mattei s Love in the Time of Money is a...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    filtered_text = []\n",
    "    for word in text.split():\n",
    "        if not word in stop_words:\n",
    "            filtered_text.append(word)\n",
    "    return \" \".join(filtered_text)\n",
    "df['review'] = df['review'].apply(remove_stop_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewers mentioned watching 1 Oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonderful way spend time hot summer ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically family little boy Jake thinks zombie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love Time Money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One reviewers mentioned watching 1 Oz episode ...  positive\n",
       "1  A wonderful little production The filming tech...  positive\n",
       "2  I thought wonderful way spend time hot summer ...  positive\n",
       "3  Basically family little boy Jake thinks zombie...  negative\n",
       "4  Petter Mattei Love Time Money visually stunnin...  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    return \" \".join([ps.stem(x) for x in text.split()])\n",
    "df['review'] = df['review'].apply(apply_stemming)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 Oz episod hook they...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonder littl product the film techniqu unass...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonder way spend time hot summer wee...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one review mention watch 1 Oz episod hook they...  positive\n",
       "1  A wonder littl product the film techniqu unass...  positive\n",
       "2  I thought wonder way spend time hot summer wee...  positive\n",
       "3  basic famili littl boy jake think zombi closet...  negative\n",
       "4  petter mattei love time money visual stun film...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('imdb_clean.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].apply(lambda x: 0 if x == 'negative' else 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 Oz episod hook they...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonder littl product the film techniqu unass...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonder way spend time hot summer wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review mention watch 1 Oz episod hook they...          1\n",
       "1  A wonder littl product the film techniqu unass...          1\n",
       "2  I thought wonder way spend time hot summer wee...          1\n",
       "3  basic famili littl boy jake think zombi closet...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = word_tokenize, max_features=200)\n",
    "text_counts = count_vector.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model(alg: str):\n",
    "    model = None\n",
    "    if alg == 'logistic_regression':\n",
    "        model = GridSearchCV(\n",
    "            LogisticRegression(n_jobs=-1),\n",
    "            param_grid={\n",
    "                'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'class_weight': [None, 'balanced']\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "    elif alg == 'decision_tree':\n",
    "        model = GridSearchCV(\n",
    "            DecisionTreeClassifier(),\n",
    "            param_grid={\n",
    "                'criterion': ['gini', 'entropy'], \n",
    "                'splitter': ['best', 'random'],\n",
    "                'min_samples_split': [4, 8, 16], \n",
    "                'min_samples_leaf': [1, 2, 4, 8],\n",
    "                'max_depth': [None, 4, 8],\n",
    "                'class_weight': [None, 'balanced']\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "    elif alg == 'random_forest':\n",
    "        model = GridSearchCV(\n",
    "            RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "            param_grid={\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'min_samples_split': [16, 20, 24, 28, 32], \n",
    "                'max_depth': [None, 4, 8],\n",
    "                'class_weight': [None, 'balanced']\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "    elif alg == 'knn':\n",
    "        model = GridSearchCV(\n",
    "            KNeighborsClassifier(),\n",
    "            param_grid={\n",
    "                'n_neighbors': [3,5,7,9],\n",
    "                'weights': ['uniform', 'distance']\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif alg == 'svm_linear':\n",
    "        model = GridSearchCV(\n",
    "            LinearSVC(),\n",
    "            param_grid={\n",
    "                'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'class_weight': [None, 'balanced']\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif alg == 'svm_kernel':\n",
    "        model = GridSearchCV(\n",
    "            SVC(),\n",
    "            param_grid={\n",
    "                'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'kernel': ['poly', 'rbf'],\n",
    "                'degree': [2, 3, 4],\n",
    "                'class_weight': [None, 'balanced']\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif alg == 'xgboost':\n",
    "        model = GridSearchCV(\n",
    "            XGBClassifier(n_estimators=50),\n",
    "            param_grid={\n",
    "                'max_depth': [None, 4, 8],\n",
    "                'scale_pos_weight': [1, (549 / 342)] # neg / pos\n",
    "            },\n",
    "            scoring='f1',\n",
    "            cv=StratifiedKFold(5),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_features(train_index, test_index):\n",
    "    X = text_counts\n",
    "    y = df['sentiment'].values\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  70 | elapsed:    1.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  70 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  70 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1425 out of 1440 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1425 out of 1440 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1425 out of 1440 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1425 out of 1440 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1425 out of 1440 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1425 out of 1440 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:    6.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:    7.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:    7.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    7.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:    7.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:    7.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:    7.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    7.4s finished\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for alg in ['logistic_regression', 'decision_tree', 'random_forest', 'knn' ]:\n",
    "    folds = 10\n",
    "    cv = StratifiedKFold(folds, shuffle=True, random_state=42)\n",
    "    metrics_train = np.zeros(shape=(folds, 4))\n",
    "    metrics_test = np.zeros(shape=(folds, 4))\n",
    "\n",
    "    for fold, (train, test) in enumerate(cv.split(text_counts, df['sentiment'].values)):\n",
    "        x_train, y_train, x_test, y_test = return_features(train, test)\n",
    "        \n",
    "\n",
    "        model = choose_model(alg)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        accuracy = accuracy_score(y_train, y_pred_train)\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(y_train, y_pred_train, average='binary')\n",
    "        metrics_train[fold, 0] = accuracy\n",
    "        metrics_train[fold, 1] = precision\n",
    "        metrics_train[fold, 2] = recall\n",
    "        metrics_train[fold, 3] = fscore\n",
    "\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "        metrics_test[fold, 0] = accuracy\n",
    "        metrics_test[fold, 1] = precision\n",
    "        metrics_test[fold, 2] = recall\n",
    "        metrics_test[fold, 3] = fscore\n",
    "\n",
    "    results[alg] = {\n",
    "        'Train - Accuracy': metrics_train[:,0].mean(),\n",
    "        'Train - Precision': metrics_train[:,1].mean(),\n",
    "        'Train - Recall': metrics_train[:,2].mean(),\n",
    "        'Train - Fscore': metrics_train[:,3].mean(),\n",
    "        'Test - Accuracy': metrics_test[:,0].mean(),\n",
    "        'Test - Precision': metrics_test[:,1].mean(),\n",
    "        'Test - Recall': metrics_test[:,2].mean(),\n",
    "        'Test - Fscore': metrics_test[:,3].mean(),\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "Test - Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "def best_algorithm(results, metric_to_observe):\n",
    "    best_algotithm = \"\"\n",
    "    best_value = 0\n",
    "    \n",
    "    for algorithm_name, algorithm_metrics in results.items():\n",
    "        for metric_name, metric_value in algorithm_metrics.items():\n",
    "            if metric_name == metric_to_observe:\n",
    "                if metric_value > best_value:\n",
    "                    best_value = metric_value\n",
    "                    best_algotithm = algorithm_name\n",
    "    return (best_algotithm, metric_to_observe, best_value)\n",
    "\n",
    "best_acurracy_results = best_algorithm(results, \"Test - Accuracy\")\n",
    "\n",
    "best_algotithm, metric_to_observe, best_value = best_acurracy_results\n",
    "print(best_algotithm)\n",
    "print(\"{} = {}\".format(metric_to_observe, best_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       115\n",
      "           1       0.70      0.73      0.71        85\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.74      0.75      0.75       200\n",
      "weighted avg       0.75      0.75      0.75       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(10, shuffle=True, random_state=42)\n",
    "ground_truth = list()\n",
    "predicted = list()\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(text_counts, df['sentiment'].values)):\n",
    "    x_train, y_train, x_test, y_test = return_features(train, test)\n",
    "\n",
    "    best_algotithm, _, _ = best_acurracy_results\n",
    "    model = choose_model(best_algotithm)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_predict = model.predict(x_test)\n",
    "\n",
    "    ground_truth.extend(y_test)\n",
    "    predicted.extend(y_predict)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(classification_report(ground_truth, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(ground_truth, predicted)\n",
    "cm = np.transpose(cm.T / cm.astype(np.float).sum(axis=1))\n",
    "\n",
    "plt.title(\"confusion matrix - sentiment prediction\")\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='rocket_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_complete = x_train\n",
    "y_complete = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_production_algorithm(algorithm, parameters):\n",
    "    if algorithm == 'logistic_regression':\n",
    "            return LogisticRegression(**parameters)\n",
    "    elif algorithm == 'decision_tree':\n",
    "            return DecisionTreeClassifier(**parameters)\n",
    "    elif algorithm == 'random_forest':\n",
    "            return RandomForestClassifier(**parameters),\n",
    "    elif algorithm == 'knn':\n",
    "            return KNeighborsClassifier(**parameters)\n",
    "    elif algorithm == 'svm_linear':       \n",
    "            return LinearSVC(**parameters),     \n",
    "    elif algorithm == 'svm_kernel':\n",
    "            return SVC(**parameters),\n",
    "    elif algorithm == 'xgboost':\n",
    "            return XGBClassifier(**parameters)\n",
    "\n",
    "best_algorithm, _, _ = best_acurracy_results\n",
    "production_model = get_production_algorithm(best_algorithm, model.best_params_)\n",
    "production_model.fit(x_complete, y_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_text(text):\n",
    "    return [apply_stemming(remove_stop_words(clean_punctuation(clean_html_tags(text))))]\n",
    "\n",
    "def predict_text(text):\n",
    "    return ['negative', 'positive'][production_model.predict(count_vector.transform(compile_text(text)))[0]]\n",
    "\n",
    "predict_text(\"I Hate This Movie this shit is dull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with nltk Sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text_nltk(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    scores = sia.polarity_scores(text)\n",
    "    if (scores['neg'] > scores['pos']):\n",
    "        return 'negative'\n",
    "    return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "        (\"VADER is smart, handsome, and funny.\", 'positive'), # positive sentence example\n",
    "        (\"VADER is smart, handsome, and funny and a good guy!\", 'positive'), # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
    "        (\"VADER is very smart and greate man.\", 'positive'),  # booster words handled correctly (sentiment intensity adjusted)\n",
    "        (\"VADER is VERY SMART, handsome, and FUNNY.\", 'positive'),  # emphasis for ALLCAPS handled\n",
    "        (\"VADER is VERY SMART, handsome, and FUNNY!!!\", 'positive'),# combination of signals - VADER appropriately adjusts intensity\n",
    "        (\"VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\", 'positive'),# booster words & punctuation make this close to ceiling for score\n",
    "        (\"The book was good.\", 'positive'),         # positive sentence\n",
    "        (\"The book was kind of good.\", 'positive'), # qualified positive sentence is handled correctly (intensity adjusted)\n",
    "        (\"The characters are uncompelling and the dialog is not great.\", 'negative'), # mixed negation sentence\n",
    "        (\"A really bad, horrible book.\", 'negative'),       # negative sentence with booster words\n",
    "        (\"At least it isn't a horrible book.\", 'negative'), # negated negative sentence with contraction\n",
    "        (\"Today sucks\", 'negative'),     #  negative slang handled\n",
    "        (\"Today sucks very very sucks!\", 'negative'),    #  negative slang with punctuation emphasis handled\n",
    "        (\"Today sucks, but maybe wikk suck even more!\", 'negative'),    #  negative slang with capitalization emphasis\n",
    "        (\"Today kinda sucks! But I'll get by, lol\", 'negative') # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_truth=0\n",
    "positive_truth=0\n",
    "\n",
    "negative_mine=0\n",
    "positive_mine=0\n",
    "\n",
    "negative_nltk=0\n",
    "positive_nltk=0\n",
    "\n",
    "for text, sentiment in sentences:\n",
    "    \n",
    "    if sentiment == 'negative':\n",
    "        negative_truth += 1\n",
    "    else:\n",
    "        positive_truth += 1\n",
    "        \n",
    "    if predict_text(text) == 'negative':\n",
    "        negative_mine += 1\n",
    "    else:\n",
    "        positive_mine += 1\n",
    "    \n",
    "    if predict_text_nltk(text) == 'negative':\n",
    "        negative_nltk += 1\n",
    "    else:\n",
    "        positive_nltk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_truth=7\n",
      "negative_mine=13\n",
      "negative_nltk=5\n",
      "\n",
      "positive_truth=8\n",
      "positive_mine=2\n",
      "positive_nltk=10\n"
     ]
    }
   ],
   "source": [
    "print (\"negative_truth={}\".format(negative_truth))\n",
    "print (\"negative_mine={}\".format(negative_mine))\n",
    "print (\"negative_nltk={}\".format(negative_nltk))\n",
    "print()\n",
    "print (\"positive_truth={}\".format(positive_truth))\n",
    "print (\"positive_mine={}\".format(positive_mine))\n",
    "print (\"positive_nltk={}\".format(positive_nltk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
